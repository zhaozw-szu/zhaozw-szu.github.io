<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>AdaIFL:Adaptive Image Forgery Localization via a Dynamic and Importance-aware Transformer Network | zhaozw后院</title><meta name="author" content="Zhaozw"><meta name="copyright" content="Zhaozw"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="发表于ECCV2024，提出了AdaIFL，为不同的网络组件定制不同的专家组，构建多个不同的特征子空间，利用自适应激活的专家网络，AdaIFL可以捕获与伪造模式相关的判别特征，增强了模型的泛化能力。提出了一种特征重要性感知注意力，自适应地感知不同区域的重要性，并将区域特征聚集成可变长度的标记，将模型的注意力导向更有区别和信息的区域。">
<meta property="og:type" content="article">
<meta property="og:title" content="AdaIFL:Adaptive Image Forgery Localization via a Dynamic and Importance-aware Transformer Network">
<meta property="og:url" content="https://zhaozw-szu.github.io/AdaIFL/index.html">
<meta property="og:site_name" content="zhaozw后院">
<meta property="og:description" content="发表于ECCV2024，提出了AdaIFL，为不同的网络组件定制不同的专家组，构建多个不同的特征子空间，利用自适应激活的专家网络，AdaIFL可以捕获与伪造模式相关的判别特征，增强了模型的泛化能力。提出了一种特征重要性感知注意力，自适应地感知不同区域的重要性，并将区域特征聚集成可变长度的标记，将模型的注意力导向更有区别和信息的区域。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zhaozw-szu.github.io/postimages/AdaIFL/image-20250106165435130.png">
<meta property="article:published_time" content="2024-11-19T13:12:46.000Z">
<meta property="article:modified_time" content="2025-02-13T14:14:52.295Z">
<meta property="article:author" content="Zhaozw">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhaozw-szu.github.io/postimages/AdaIFL/image-20250106165435130.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhaozw-szu.github.io/AdaIFL/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'AdaIFL:Adaptive Image Forgery Localization via a Dynamic and Importance-aware Transformer Network',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-13 22:14:52'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" type="text/css" href="/config/css/heoMainColor.css"><link rel="stylesheet" type="text/css" href="/config/css/categoryBar.css"><link rel="stylesheet" type="text/css" href="/config/css/icat.css"><link rel="stylesheet" type="text/css" href="/config/css/emoticon.css"><link rel="stylesheet" href="https://npm.elemecdn.com/swiper@8.4.2/swiper-bundle.min.css" media="print" onload="this.media='all'"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">91</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-chart-simple"></i><span> 文库</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/rank/"><i class="fa-fw fas fa-line-chart"></i><span> 期刊等级</span></a></li><li><a class="site-page child" href="/dataset/"><i class="fa-fw fas fa-database"></i><span> 数据集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-sun"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li><li><a class="site-page child" href="/essay/"><i class="fa-fw fas fa-music"></i><span> 即刻短文</span></a></li><li><a class="site-page child" href="/game/"><i class="fa-fw fas fa-gamepad"></i><span> 小游戏</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/postimages/AdaIFL/image-20250106165435130.png')"><nav id="nav"><span id="blog-info"><a href="/" title="zhaozw后院"><img class="site-icon" src="/img/favicon.png"/><span class="site-name">zhaozw后院</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-chart-simple"></i><span> 文库</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/rank/"><i class="fa-fw fas fa-line-chart"></i><span> 期刊等级</span></a></li><li><a class="site-page child" href="/dataset/"><i class="fa-fw fas fa-database"></i><span> 数据集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-sun"></i><span> 关于</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li><li><a class="site-page child" href="/essay/"><i class="fa-fw fas fa-music"></i><span> 即刻短文</span></a></li><li><a class="site-page child" href="/game/"><i class="fa-fw fas fa-gamepad"></i><span> 小游戏</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">AdaIFL:Adaptive Image Forgery Localization via a Dynamic and Importance-aware Transformer Network</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">创建于</span><time class="post-meta-date-created" datetime="2024-11-19T13:12:46.000Z" title="创建于 2024-11-19 21:12:46">2024-11-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-13T14:14:52.295Z" title="更新于 2025-02-13 22:14:52">2025-02-13</time><span class="post-meta-separator">|</span><i class="fas fa-star fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><span class="post-rank">B类会议,ECCV,2024</span></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%9B%BE%E5%83%8F%E7%AF%A1%E6%94%B9%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/">图像篡改检测与定位</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="AdaIFL:Adaptive Image Forgery Localization via a Dynamic and Importance-aware Transformer Network"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>AdaIFL: Adaptive Image Forgery Localization via a Dynamic and
Importance-aware Transformer Network</p>
<center>
Yuxi Li1 , Fuyuan Cheng1 , Wangbo Yu1 , Guangshuo Wang1 , Guibo Luo1 ⋆ ,
and Yuesheng Zhu1 ⋆ School of Electronic and Computer Engineering,
Peking University yuxili@stu.pku.edu.cn, {luogb,zhuys}<span
class="citation" data-cites="pku.edu.cn">@pku.edu.cn</span>
</center>
<h1 id="摘要">摘要</h1>
<p>​  图像处理和操作技术的快速发展给多媒体取证，特别是图像伪造定位（IFL）带来了前所未有的挑战。<br/>​  本文解决了IFL中的两个关键挑战：<br/>​  (1)各种伪造技术留下了明显的法医痕迹。然而，现有的模型忽略了伪造模式之间的差异。伪造技术的多样性使得单一的静态检测方法和网络结构具有普遍适用的挑战性。为了解决这个问题，我们提出了AdaIFL，这是一个动态的IFL框架，它为不同的网络组件定制不同的专家组，构建多个不同的特征子空间。通过利用自适应激活的专家网络，AdaIFL可以捕获与伪造模式相关的判别特征，增强了模型的泛化能力。<br/>​  (2)许多法医鉴定的痕迹和手工艺品都位于伪造区域的边界上。现有的模型要么忽略了区分信息的差异，要么利用边缘监督损失来迫使模型关注区域边界。这种硬约束的方法容易产生注意力偏差，导致模型对图像边缘过于敏感，或无法精细地捕捉到所有的法医痕迹。在本文中，我们提出了一种特征重要性感知注意力，一种灵活的方法，自适应地感知不同区域的重要性，并将区域特征聚集成可变长度的标记，将模型的注意力导向更有区别和信息的区域。<br/>​  在基准数据集上的大量实验表明，AdaIFL优于最先进的图像伪造定位方法。我们的代码可以在https://github.com/LMIAPC/AdaIFL上找到。</p>
<p>关键词：图像伪造定位·动态网络架构·特征重要性意识注意</p>
<h1 id="介绍">1介绍</h1>
<p>​  随着图像编辑和处理技术的快速发展，人们更容易创建真实的伪造图像，这可能会被滥用来传播恶意信息，对媒体内容[31]的安全性构成重大挑战。因此，开发一种有效的对伪造图像的识别和定位方法具有重要意义。<br/>​  近年来，研究人员提出了许多基于深度学习的方法[14,25,37,39,43]来检测和定位伪造域，取得了重大进展。然而，这些方法在现实生活中仍然不能取得令人满意的结果，主要面临两个挑战：<br/>​  (1)制造商拥有各种操作图像的技术和工具，包括对象插入、删除、克隆和失真，每一种都留下不同的伪影和法医痕迹。如图1
(a)所示，现有的方法在处理具有不同伪造线索和模式的伪造图像时缺乏适应性。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241119211919428.png"
alt="image-20241119211919428" />
<figcaption aria-hidden="true">image-20241119211919428</figcaption>
</figure>
<p>图1：我们的贡献的说明。现有的方法在处理具有不同伪造线索和模式的伪造图像时缺乏适应性和灵活性，导致错误警报、漏检，无法准确定位细微的伪造区域。相比之下，我们的模型结合了动态路由和特征输入感知机制，可以动态地处理不同的伪造图像样本，并自适应地感知不同区域的重要性，在这些方面表现出优越的性能。</p>
<p>​  (2)通过图像操作产生的人工制品和法医痕迹主要位于伪造区域的边界上。这些痕迹是微妙而微妙的，涉及到光线、纹理或去除小物体的微小变化。由于稀疏的特性、有限的上下文信息和易受损坏的漏洞，这给伪造定位带来了重大挑战。为了捕获微妙的伪影和法医痕迹，一些方法，如IML-ViT
[21]和MVSS-Net
[5]，使用边缘监督损失来迫使模型集中于区域边界。然而，如图1
(b)所示，这种硬约束的方法很容易导致注意力偏差，导致模型对图像边缘过于敏感，或无法精细地捕捉到所有的法医痕迹。这就导致了诸如错误警报、检测遗漏以及无法准确定位具有尖锐边界的伪造区域等问题。因此，为了防止模型过度依赖边界区域，忽视其他关键特征，必须实现更加灵活和适当的平衡。<br/>​  在本文中，我们提出了一种新的动态和重要性感知的变压器网络AdaIFL。为了解决在处理伪造样本时适应性不足的挑战，我们提出了一个新的动态框架，将动态路由机制的概念合并到IFL中。我们的框架包括一个基于transformer的动态编码器和一个轻量级的动态解码器。我们在不同的网络组件中定制不同的专家组，构建多个不同的特征子空间。通过门控网络的路由，伪造的图像样本可以选择性地激活网络的不同部分，从而在各自的特征子空间中挖掘出与伪造模式相关的鉴别特征。这大大提高了模型的泛化能力。<br/>​  为了避免模型对伪造区域周围的边界伪影的过度敏感或忽视，我们提出了特征重要性感知注意（FIA，feature
importance-aware
attention），这是一种灵活的方法，可以自适应地感知不同区域的重要性。其中一个关键组件是自适应token聚合器（ATA，adaptive
token
aggregator），它由三个部分组成：重要性感知区域分区、聚合规模分配和自适应token聚合。ATA的目标是基于区域特征的鉴别信息，将区域特征动态聚合为可变长度tokens，为不同尺度和形状的伪造区域建模。具体来说，我们设计了一个评分网络来量化每个图像特征的重要性。根据重要性评分，将整个图像区域划分为多个子区域。然后利用一种简单而有效的自适应机制对判别信息进行评估，从而确定每个子区域的聚集规模。特别是，较小的聚合尺度被分配为具有更多区别区域的区域生成更多的特征标记，如图像处理边界。最后，利用聚类算法在聚合尺度的引导下对token进行合并，得到了紧凑而又具有高度判别性的token表示。FIA将模型的注意力导向更有鉴别力的区域，显著提高了模型准确定位各种伪造区域的能力。<br/>​  我们的主要贡献总结如下：</p>
<ul>
<li>我们提出了AdaIFL，一个新的动态和重要性感知的IFL框架。据我们所知，这是第一次将动态路由机制引入IFL，使其在该领域的开创性贡献。</li>
<li>我们提出了一种特征重要性感知注意，即自适应地感知不同区域的重要性，提高了模型准确定位不同伪造区域的能力。</li>
<li>我们在几个基准上进行了广泛的实验，并证明了AdaIFL在定性和定量上优于现有的最先进的方法。</li>
</ul>
<h1 id="相关工作">2相关工作</h1>
<h1 id="方法">3方法</h1>
<h2 id="框架概述">3.1框架概述</h2>
<p>​  在本文中，我们提出了AdaIFL，一个动态的和重要性感知的图像伪造定位框架。如图2所示，AdaIFL将动态路由机制引入到IFL中。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241119220644639.png"
alt="image-20241119220644639" />
<figcaption aria-hidden="true">image-20241119220644639</figcaption>
</figure>
<p>图2： (a)
AdaIFL框架。AdaIFL以可疑的图像作为输入，然后利用一个基于transformer的动态编码器来提取多级特征。这些特征被传递到一个轻量级的动态解码器中，进行多尺度的特征融合，生成一个空间定位图来预测伪造的区域。(b)动态transformer块。AdaIFL框架将动态路由机制的概念整合到transformer块（FIATB和GTB）中，在注意力层和MLP层中引入多个特定的专家网络，以挖掘出与伪造模式相关的区别特征。FIATB和GTB分别表示特征重要性感知的transformer块和全局transformer块。</p>
<p>​  它为不同的网络组件定制了不同的专家网络，构建了多个特征子空间来专门学习不同的伪造模式。具体来说，该框架由一个基于transformer的动态编码器和一个轻量级的动态解码器组成。该编码器包括四个阶段，每个阶段包括两个堆叠的特征重要性感知transformer块（FIATB）和一个全局transformer块（GTB）。此外，我们提出了一个动态解码器来融合多阶段特征，并预测伪造区域的空间定位图。其详细结构如图4
(a)所示，包括多尺度特征融合（MSFF）和动态解码两个过程。在下面的章节中，我们将详细介绍AdaIFL的几个关键组件。</p>
<h2 id="动态transformer组件">3.2动态transformer组件</h2>
<p>​  <strong>准备工作：专家网络的混合。</strong><br/>​  专家网络的混合层（MoE，Mixture
of Experts）包括一组专家网络，记为<span
class="math inline">\(E_{1},E_{2},\cdot\cdot,E_{N}\)</span>，以及记为<span
class="math inline">\({\mathcal{G}}\)</span>的路由网络。在网络的不同组件中，每个专家网络可以实现为注意层、MLP层或卷积层。路由网络<span
class="math inline">\({\mathcal{G}}\)</span>负责确定利用每个专家网络<span
class="math inline">\(E_i\)</span>的概率，并选择前k个专家作为最终输出的贡献者。<span
class="math inline">\({\mathcal{G}}\)</span>可以根据各种形式选择专家，如单个token、输入样本或任务嵌入：
<span class="math display">\[\displaystyle{\cal
G}=\left\{\begin{array}{l l}G_{t o k e
n}\left(x_{i}\right),&amp;\mathrm{Token}\mathrm{-}\mathrm{level}\\ G_{s
a m p l e}\left(X\right),&amp;\mathrm{Sample}\mathrm{-}\mathrm{level}\\
G_{t a s k}\left(e m b e d(i d_{t a s
k})\right),&amp;\mathrm{Task}\mathrm{-}\mathrm{level}\end{array}\right.\]</span>
​  其中，<span
class="math inline">\(G\)</span>定义了门决策的特定路由策略，<span
class="math inline">\(\textstyle
X=\{x_{i}\}_{i=1}^{L}\)</span>是当前样本中所有token的序列。专家网络混合层的最终输出是来自选定的专家网络<span
class="math inline">\(E\subset\{E_{1},E_{2}\cdot\cdot\cdot
E_{N}\}\)</span>： <span class="math display">\[y=\sum_{i\in E}{\cal
G}\left(x\right)\cdot E_{i}\left(x\right)\]</span>
​  <strong>专家网络混合层的动态transformer组件。</strong><br/>​  我们进一步将专家网络混合层的动态路由概念纳入到transformer架构中。具体来说，我们向多个特定的专家网络引入注意力机制和MLP层。我们鼓励这些专家网路探索与伪造模式相关的独特的工件和法医痕迹，以增强网络的泛化能力。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241119224743855.png"
alt="image-20241119224743855" />
<figcaption aria-hidden="true">image-20241119224743855</figcaption>
</figure>
<p>​  如图2 (b)所示，我们用一组并行注意的专家网路和一组
sample-level的路由器替换原来的注意层，用一组并行MLP专家和一组token级路由器替换原来的MLP层。在形式上，AdaIFL编码器的transformer块可以表述为：
<span
class="math display">\[\begin{array}{c}{X_{l}^{\prime}=\mathrm{MoE}\mathrm{-Att}\left(\mathrm{LN}\left(X_{l-1}\right)\right)+X_{l-1}}\\
X_{l}=\mathrm{MoE}\mathrm{-FFN}\left(\mathrm{LN}\left(X_{l}^{\prime}\right)\right)+X_{l}^{\prime}\end{array}\]</span>
​  其中，<span
class="math inline">\(\mathrm{MoE}-\mathrm{Att}(X)=\sum_{i\in
E_{\mathrm{Att}}}G_{s a m p l e}^{i}\left(X\right)\cdot
E_{\mathrm{Att}}^{i}\left(X\right)\)</span>，<span
class="math inline">\(\mathrm{MoE}-{\mathsf {FFN}}(x)=\sum_{i\in
E_{MLP}}G_{t o k e n}^{i}\left(x\right)\cdot
E_{\mathrm{MLP}}^{i}\left(x\right)\)</span>，LN表示图层的归一化。值得注意的是，我们在FIATB中对MoE采用了特征重要性感知的注意力，详见Sec3.3。在GTB中，使用了标准的全局自注意机制。</p>
<h2 id="特征重要性感知的注意力">3.3特征重要性感知的注意力</h2>
<p>​  为了避免模型对操纵边界区域的过度敏感或忽视，我们提出了一种特征重要性感知的注意力，即自适应地感知不同区域的重要性，并将区域特征聚合成可变token，对不同尺度、形状和内容的伪造区域进行建模。整体结构如图3所示。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241119225539278.png"
alt="image-20241119225539278" />
<figcaption aria-hidden="true">image-20241119225539278</figcaption>
</figure>
<p>图3： (a)特征重要性感知的注意力（FIA，feature importance-aware
attention）例证。(b)自适应token聚合器（ATA，Adaptive token
aggregator）。从左到右，ATA涉及三个过程：重要性感知区域分区、聚合规模分配和自适应token聚合。</p>
<h3
id="重要性感知的区域分区"><strong>重要性感知的区域分区。</strong></h3>
<p>​  我们设计了一个评分网络来评估区域特征对IFL任务的重要性，记为<span
class="math inline">\(f_s\)</span>，它是一个由两个MLP层组成的轻量级模块。具体来说，给定一个输入特征<span
class="math inline">\(X\in\mathbb{R}^{N\times
d}\)</span>，其中d表示每个特征标记的维数，N表示特征标记的数量。<span
class="math inline">\(f_s\)</span>用于量化每个特征标记<span
class="math inline">\(x_i\)</span>的重要性。 <span
class="math display">\[s_{i}=f_{s}(x_{i}),\,i=1,\cdot\cdot\cdot,\,N\]</span>
​  此外，根据重要性分数对特征token进行排序，得到一组特征token及其各自的分数，表示为<span
class="math inline">\(\left\{x_{i}^{\prime}\right\}_{i=1}^{N}\)</span>和<span
class="math inline">\(\left\{s_{i}^{\prime}\right\}_{i=1}^{N}\)</span>。此外，根据token的排序列表，将整个图像区域划分为m个不规则子区域<span
class="math inline">\(\left\{R_{i}\right\}_{i=1}^{m}\)</span>，每个子区域包含<span
class="math inline">\(N_{R_i}\)</span>标记。</p>
<h3 id="聚合规模分配"><strong>聚合规模分配</strong></h3>
<p>​  基于每个区域对伪造定位的重要性，动态调整聚合尺度，对不同尺度和形状的伪造区域进行建模。为了实现这一点，我们使用了一个简单的MLP层来将区域重要性的分布转换为信息密度因子。这些因素被用来评估每个图像区域的鉴别信息，表示为<span
class="math inline">\(\rho=\left\{\rho_{1},\ \rho_{2},\
\ldots,\rho_{m}\right\}\)</span>。然后应用Softmax函数对密度因子进行归一化，并利用它们生成不同区域的聚集尺度。这可以表述为：
<span
class="math display">\[\hat{\rho}_{i}=\frac{e^{\rho_{i}}}{\sum_{i=1}^{m}e^{\rho_{i}}},i=1,\cdot\cdot,m\]</span>
， <span
class="math display">\[c_{i}=N_{\lambda}\hat{\rho}_{i},\alpha_{i}=\frac{N_{R_{i}}}{c_{i}}\]</span></p>
<p>​  式中，<span
class="math inline">\(N_{\lambda}\)</span>为预定义的token总数<span
class="math inline">\((N_{\lambda}\ll N)\)</span>，<span
class="math inline">\(c_i\)</span>表示分配给子区域<span
class="math inline">\(R_i\)</span>的token数，<span
class="math inline">\(\alpha_{i}\)</span>表示<span
class="math inline">\(R_i\)</span>的聚集规模。这种自适应方法将更小的聚集规模分配到更有区别的区域，产生更多的特征token。相反，其他区域使用更大的规模来进行更粗的token聚合。</p>
<h3 id="自适应token聚合ata"><strong>自适应token聚合ATA</strong></h3>
<p>​  在分配了相应的聚合规模之后，我们需要进一步考虑如何聚合token。直观地说，聚合具有相似语义信息的token可以避免对冗余特征的过度关注和对微妙特征的关注不足。受[7,41]的启发，我们使用聚类算法进行token聚类和合并，从而得到更准确和紧凑的token表示。具体来说，我们使用DPC-KNN算法[7]来进行token聚类，这是一种基于密度峰值的k-最近邻聚类算法。在此算法的基础上，根据每个区域的特征token的相似性划分为<span
class="math inline">\(c_i\)</span>不同的聚类。在聚合过程中，将重要性分数作为权重分配给同一集群内的token，强调不同token的重要性。因此，可以获得每个集群的token表示：
<span class="math display">\[\hat{x}_{i}=\frac{\sum_{j\in
c_{i}}e^{s_{j}}x_{j}}{\sum_{j\in c_{i}}e^{s_{j}}}\]</span>
​  最后，将来自所有区域的聚合token连接起来，得到最终的token表示<span
class="math inline">\(\hat{X}\in\mathbb{R}^{N_{\lambda}\times
d}\)</span>。</p>
<h3
id="特征重要性感知的注意力fia"><strong>特征重要性感知的注意力FIA</strong></h3>
<p>​  我们提出了基于自适应token聚合器的特征重要性感知注意力（FIA），以避免过度关注冗余特征或忽略局部细节。具体来说，我们将原始特征token<span
class="math inline">\(X\in\mathbb{R}^{N\times
d}\)</span>投影为查询Q，将聚合token<span
class="math inline">\(\hat{X}\in\mathbb{R}^{N_{\lambda}\times
d}\)</span>投影为键K和值V。该流程的定义为： <span
class="math display">\[\begin{array}{l}{Q=X
W^{q},K=\hat{X}W^{k},V=\hat{X}W^{v}}\\
\mathrm{FIA}(Q,K,V)=\mathrm{Softmax}\left({\cfrac{Q
K^{\top}}{\sqrt{d}}}\right)V\end{array}\]</span> ​  其中，<span
class="math inline">\(W^{q},W^{k},W^{v}\in\mathbb{R}^{d\times
d}\)</span>为可学习矩阵。<br/>​  如图6所示，FIA将模型的注意力转向更区分的区域，提高了伪造定位的性能。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241119231517507.png"
alt="image-20241119231517507" />
<figcaption aria-hidden="true">image-20241119231517507</figcaption>
</figure>
<p>图6：自适应token聚合器（ATA）和特征重要性感知注意力（FIA）的可视化。从左到右，我们显示伪造的图像、ground-truth掩模、特征图的GradCAM和没有（w/o）ATA，没有（w/o）FIA和完整设置的预测结果。</p>
<p>​  这是由于有几个优点。<br/>​  (1)区域划分机制限制了真实区域和伪造区域之间的相互作用，缓解了特征耦合问题。许多伪造技术旨在创建语义上一致的和感知上令人信服的篡改图像的视觉欺骗。因此，直接聚类[7,41]无意中导致了特征耦合。如图6所示，ATA的区域划分机制缓解了这个问题，减少了误报。<br/>​  (2)自适应聚合机制可以根据不同区域的重要性动态调整聚合规模，使模型能够灵活地适应伪造区域的各种尺度和形状。</p>
<h2 id="动态解码器">3.4动态解码器</h2>
<figure>
<img src="../postimages/AdaIFL/image-20241120094237190.png"
alt="image-20241120094237190" />
<figcaption aria-hidden="true">image-20241120094237190</figcaption>
</figure>
<figure>
<img src="../postimages/AdaIFL/image-20241120094333966.png"
alt="image-20241120094333966" />
<figcaption aria-hidden="true">image-20241120094333966</figcaption>
</figure>
<p>图4：
(a)动态解码器示意图。它由多阶段特征融合（MSFF）和动态解码器组成。(b)从左到右是阶段1、阶段2、阶段3、阶段4和MSFF的输出特性映射的GradCAM。MSFF模块集成了多阶段的特性，提高了伪造定位的性能。</p>
<p>​  如图4
(a)所示，动态解码器由多阶段特征融合（MSFF）和动态解码两个过程组成，旨在融合多阶段特征，实现更好的定位性能。如图4
(b)所示，每个阶段都侧重于捕获不同级别的特征。因此，MSFF被提出充分利用特征在不同阶段的表达能力，并捕获更多的鉴别信息。<br/>​  具体来说，MSFF利用从transformer的四个阶段中提取的特征图<span
class="math inline">\(F_1\)</span>、<span
class="math inline">\(F_2\)</span>、<span
class="math inline">\(F_3\)</span>和<span
class="math inline">\(F_4\)</span>作为输入，并沿着通道维度将每个特征图分成四个部分。然后，我们从每个特征图中选择一部分特征，并将它们连接起来，得到四个融合的特征。然后，利用不同核大小的深度可分离卷积来处理这四个融合特征，捕获多尺度特征。此外，利用群卷积[18]提取有价值的信息，并从融合的特征中过滤出冗余的特征表示。此外，利用群卷积[18]提取有价值的信息，并从融合的特征中过滤出冗余的特征表示。这一点可以表述如下：
<span
class="math display">\[\begin{array}{l}Z_{i}=\mathrm{Concat}\left(F_{1}\left[i\right],F_{2}\left[i\right],F_{3}\left[i\right],F_{4}\left[i\right]\right),Z_{i}^{&#39;}=\mathrm{D
W}_{k_{i}\times k_{i}}{\left(Z_{i}\right)}\\
\hat{Z}=\mathrm{GC}\left(\mathrm{Concat}\left(Z_{1}^{&#39;},\;Z_{2}^{&#39;},\;Z_{3}^{&#39;},\;Z_{4}^{&#39;}\right)\right)\end{array}\]</span>
​  其中，<span
class="math inline">\(k_{i}\in\{3,5,7,9\}\)</span>，DW表示深度上可分离的卷积，GC表示群卷积。<br/>​  最后，我们引入了一个动态解码模块来预测输入图像的伪造区域。它涉及一组并行预测头<span
class="math inline">\(\{P_{i}\}_{i=1}^{n}\)</span>和一个样本路由器。每个预测头<span
class="math inline">\(P_i\)</span>被实现为一个1x1的卷积，即<span
class="math inline">\(P_{i}(\hat{Z})=W_{i}\hat{Z}\)</span>。在样本路由器中，我们首先执行全局平均池化来生成全局嵌入<span
class="math inline">\(\tau\)</span>。然后，通过一个全连接层和sigmoid函数，即<span
class="math inline">\(A
P\left(\hat{Z}\right)=\sigma\left(W_{a}\tau\right)\)</span>，计算每个头部的激活概率。动态解码器的最终输出是概率最高的前k个预测头的加权和：
<span class="math display">\[Y=\sum_{A P_{i}\in\mathrm{top.k}}A
P_{i}({\hat{Z}})\cdot P_{i}({\hat{Z}})\]</span></p>
<h2 id="优化">3.5优化</h2>
<p>​  为了提高模型在像素级检测伪造区域的准确性，我们利用了二进制交叉熵损失和dice损失[22]。
<span
class="math display">\[{\mathcal{L}}_{\mathrm{BCE}}\left(p,y\right)=\sum\left(-y_{i}\log
p_{i}-\left(1-y_{i}\right)\log\left(1-p_{i}\right)\right)\]</span> ，
<span
class="math display">\[\mathcal{L}_{\mathrm{Dice}}\left(p,y\right)=1-\frac{2\sum
p_{i}\cdot y_{i}}{\sum p_{i}{}^{2}+\sum y_{i}{}^{2}}\]</span>
​  其中，<span class="math inline">\(p_i\)</span>和<span
class="math inline">\(y_i\)</span>分别为伪造图像中每个像素的预测标签和ground-truth。此外，我们采用度量学习损失[13]来增加[23]后伪造图像样本中真实区域和伪造区域之间的特征分布的差异。
<span
class="math display">\[{\mathcal{L}}_{q}={\frac{1}{|A_{i}|}}\sum_{k^{+}\in
A_{i}}-\log{\frac{\exp\left(q\cdot
k^{+}/\tau\right)}{\sum_{k_{-}}\exp\left(q\cdot
k^{-}/\tau\right)}}\]</span> ​  其中，<span
class="math inline">\(k^+\)</span>和<span
class="math inline">\(q\)</span>表示真实区域的特征嵌入，<span
class="math inline">\(k^−\)</span>表示伪造区域的特征嵌入。<span
class="math inline">\(A_i\)</span>表示所有<span
class="math inline">\(k^+\)</span>的集合。结合以上所有情况，我们的最终损失函数可以表述为：
<span
class="math display">\[\mathcal{L}=\lambda_{1}\cdot\mathcal{L}_{q}+\lambda_{2}\cdot\mathcal{L}_{\mathrm{BCE}}\
+\lambda_{3}\cdot\mathcal{L}_{\mathrm{Dice}}\]</span> ​  其中，<span
class="math inline">\(\lambda_{1}\)</span>、<span
class="math inline">\(\lambda_{2}\)</span>、<span
class="math inline">\(\lambda_{3}\)</span>是平衡损失函数中这三项的参数<span
class="math inline">\((\lambda_{1}+\lambda_{2}+\lambda_{3}=1)\)</span>。在实验中，它们分别被设为0.5、0.15和0.35。</p>
<h1 id="实验">4实验</h1>
<h2 id="实验设置">4.1实验设置</h2>
<h3 id="数据集"><strong>数据集。</strong></h3>
<p>​  我们使用与[11,19]相同的数据集来训练AdaIFL。这些训练数据集包括CASIA
v2 [6]、IMD2020
[24]，以及由[19]创建的经过伪造的图像数据集，涵盖了各种类型的伪造。为了全面评估AdaIFL的泛化能力，我们对5个与训练集不重叠的数据集进行了基准测试，即CASIA
v1 [6]、Coverage[35]、DSO-1 [4]、NIST16 [10]和MISD
[16]。这些数据集覆盖了大量的伪造图像，具有不同的伪造类型和广泛分布的数据源。</p>
<h3 id="指标"><strong>指标。</strong></h3>
<p>​  在之前的大多数工作之后，我们使用像素级的曲线下面积（AUC）、F1和Union上的交集（IoU）分数作为评估指标，其中阈值默认设置为0.5。</p>
<p>​  <strong>实施细节。</strong><br/>​  AdaIFL使用PyTorch实现，并以端到端方式进行培训。在训练过程中，输入的图像被裁剪到1024×1024。为了防止训练数据集大小不平衡造成的偏差，我们采用[11,19]的方法，在每个训练时期对每个数据集进行相等的采样。此外，还采用了常用的数据增强技术，如翻转、缩放、模糊和JPEG压缩来增强数据的多样性。我们使用了一个Adam
[17]优化器，其学习速率从2×10−4衰减到1×10−7。</p>
<h2 id="与最新方法的比较">4.2与最新方法的比较</h2>
<p>​  我们仔细选择带有开放源代码和预训练模型的方法进行测试，以确保公平的比较。此外，确保这些模型的训练数据集不与测试数据集重叠是至关重要的。最后，我们选择了8种最先进的方法，以公平的方式进行全面的比较，即TruFor[11]，HiFi-IFDL[12]，CAT-Net
v2[19]，ManTraNet[37]，MVSS-Net[2]，PSCC-Net[20]，IF-OSN[36]和IML-ViT
[21]。</p>
<h3 id="定量比较">定量比较</h3>
<p>​  表1为不同模型对IOU、f1、AUC评分的定量比较结果。</p>
<hr />
<p>表1：不同图像伪造定位方法的性能比较。报告了IOU、F1和AUC评分。第一个和第二个排名分别以粗体和下划线显示。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241120112901191.png"
alt="image-20241120112901191" />
<figcaption aria-hidden="true">image-20241120112901191</figcaption>
</figure>
<hr />
<p>​  在所有比较模型中，AdaIFL达到了最先进的性能，平均IOU、F1和AUC得分分别比第二优模型高出6.6%、3.4%和1.9%。具体来说，对于F1和IOU评分，AdaIFL在CASIA、Coverage、NIST16和MISD上的定位性能最好，在DSO-1中排名第二。特别是在Coverage（复制-移动伪造数据集）上，AdaIFL的IOU和F1得分比第二优模型高出8.0%和4.6%，证明了我们的模型在抑制伪造区域和真实区域之间的特征耦合方面的突出能力。在更具挑战性的NIST16数据集上，我们的模型在IOU和F1分数上比第二优的模型高出8.7%和5.3%，在处理各种操作技术和伪造模式方面显示出非凡的泛化能力。值得注意的是，使用AUC作为度量可能会导致高估模型的性能，因为数据集的伪造像素和真实像素之间的比例高度不平衡。然而，我们的模型在所有数据集上都获得了最好的AUC分数。</p>
<h3 id="定性比较"><strong>定性比较</strong></h3>
<p>​  图5显示了不同测试图像的伪造定位结果。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241120145615997.png"
alt="image-20241120145615997" />
<figcaption aria-hidden="true">image-20241120145615997</figcaption>
</figure>
<p>​  我们的方法在几个方面都优于目前的SOTA方法。首先，我们的方法有效地减少了误报和漏检。与其他方法将非伪造区域错误识别为伪造或遗漏许多伪造区域不同，我们的方法可以准确地定位具有尖锐边界的伪造区域。其次，该方法可以准确地定位各种复杂形状的锻造区域。这在测试图像的第五行和第六行可以明显看出，其中其他方法只能预测粗略的结果，而不能捕获详细的边界。相比之下，我们的方法可以准确地定位具有复杂形状的伪造区域。第三，我们的方法在精确定位微小和微妙的伪造区域方面表现出了特殊的能力。如第三行和第六行的测试图像所示，许多方法很难识别这些小区域，而我们的方法可以准确地定位它们。</p>
<h3 id="鲁棒性分析">鲁棒性分析</h3>
<p>​  在现实世界的场景中，伪造的图像可能会经历各种后处理操作。为了评估AdaIFL对伪造定位的鲁棒性，我们使用了常用的图像退化技术，即高斯模糊、高斯噪声、伽马校正和JPEG压缩。如表2所示，在NIST16上的测试结果表明，与其他最先进的方法相比，AdaIFL对各种降解技术表现出优越的鲁棒性。</p>
<hr />
<p>表2：在不同失真条件下对NIST16数据集的定位性能。报告了IOU和F1的分数。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241120150358022.png"
alt="image-20241120150358022" />
<figcaption aria-hidden="true">image-20241120150358022</figcaption>
</figure>
<hr />
<p>​  此外，表2表明，过量的噪声（k =
23）导致了我们的模型中的次优结果。这可能是由于路由过程受到噪声的影响，导致了专家的次优选择。我们认为，设计适当的补救机制，以确保在各种退化场景中路由的准确性，可能是有益的。</p>
<h2 id="消融分析">4.3消融分析</h2>
<p>​  在本节中，我们将从特征重要性感知和动态网络结构这两个角度来分析AdaIFL中关键组件的影响。具体来说，AdaIFL通过分别在编码器（DyE）和解码器（DyD）中定制各种专家组，将动态路由的想法整合到IFL中。特征重要性感知注意注意力（FIA）自适应地感知不同区域的重要性，其中一个关键组件是自适应标记聚合器（ATA），它将区域特征聚合成可变长度的标记，将模型的注意力导向更具鉴别性和信息丰富的区域。为了评估FIA、ATA、DyE和DyD的有效性，我们分别从AdaIFL中移除每个组件，并将测试结果与CASIA和MISD数据集上的完整设置进行比较。</p>
<h3 id="特征重要性感知的影响">特征重要性感知的影响</h3>
<hr />
<figure>
<img src="../postimages/AdaIFL/image-20241120150855145.png"
alt="image-20241120150855145" />
<figcaption aria-hidden="true">image-20241120150855145</figcaption>
</figure>
<hr />
<p>​  如表3中所示，用原注意力代替FIA后，IOU得分下降5.2%，CASIA
F1得分下降3.1%，MISD IOU下降4.4%，MISD
F1下降2.2%。去除ATA后，CASIA的IOU得分分别下降了4.4%和MISD的下降了3.9%。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241120150959994.png"
alt="image-20241120150959994" />
<figcaption aria-hidden="true">image-20241120150959994</figcaption>
</figure>
<p>​  此外，图6显示，去除FIA或ATA会导致检测失误、误报和无法准确定位伪造区域等问题。AdaIFL受益于区域划分和自适应聚合机制，缓解了特征耦合的问题，提高了图像伪造定位的性能。</p>
<figure>
<img src="../postimages/AdaIFL/image-20241120151045785.png"
alt="image-20241120151045785" />
<figcaption aria-hidden="true">image-20241120151045785</figcaption>
</figure>
<p>​  此外，图4 (b)显示了变压器编码器不同阶段的特征图的GradCAM。在
FIA的指导下，AdaIFL专注于在不同的阶段捕捉不同的特征。在初始阶段，该模型对伪造区域边界的局部细节进行了优先排序，强调了对边界伪造痕迹的精细感知。在随后的阶段中，它专注于在伪造区域内捕获不同级别的特征。MSFF模块通过融合这些特性，增强了模型的表达性，从而能够更好地捕获伪造的工件和法医痕迹。</p>
<h3 id="动态网络结构的影响">动态网络结构的影响</h3>
<p>​  在AdaIFL中，我们将动态路由的概念应用于基于transformer的编码器和轻量级路由器中。</p>
<hr />
<figure>
<img src="../postimages/AdaIFL/image-20241120150855145.png"
alt="image-20241120150855145" />
<figcaption aria-hidden="true">image-20241120150855145</figcaption>
</figure>
<hr />
<p>​  如表3所示，去除动态专家组会显著降低定位性能。具体来说，从编码器中删除所有动态专家组，CASIA的IOO和F1得分下降了7.4%和4.5%，MISD的IOU和F1得分下降了3.7%和1.6%。从解码器中去除动态成分后，CASIA和MISD的IOU得分分别下降了4.9%和1.5%。这清楚地说明了动态路由概念在增强模型泛化方面的关键作用。</p>
<h1 id="结论">5结论</h1>
<p>​  本文解决了图像伪造定位的两个关键挑战：<br/>​  
(1)处理不同伪造图像的适应性不足，<br/>​  (2)捕获边界伪影的方法不灵活。<br/>​  为了解决这些问题，我们提出了一种新的动态和重要性感知的图像伪造定位框架（AdaIFL），该框架可以动态地处理不同的伪造图像样本，并自适应地感知不同区域的重要性，提高了模型的泛化能力。大量的实验表明，我们所提出的方法优于最先进的方法。</p>
<h1 id="acknowledgements"><strong>Acknowledgements</strong></h1>
<p>This work is supported by Shenzhen Science and Technology Program
(No.JCYJ20230807120800001), and 2023 Shenzhen sustainable supporting
funds for colleges and universities (No.20231121165240001). The authors
sincerely appreciate the computing environment supported by the China
Unicom Shenzhen Intelligent Computing Center.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://zhaozw-szu.github.io">Zhaozw</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://zhaozw-szu.github.io/AdaIFL/">https://zhaozw-szu.github.io/AdaIFL/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhaozw-szu.github.io" target="_blank">zhaozw后院</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/postimages/AdaIFL/image-20250106165435130.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/AIGCTraceability/" title="AIGCTraceability"><img class="cover" src="/img/coverImage/cover2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">AIGCTraceability</div></div></a></div><div class="next-post pull-right"><a href="/Image-Manipulation-Detection-With-Implicit-Neural-Representation-and-Limited-Supervision/" title="Image_Manipulation_Detection_With_Implicit_Neural_Representation_and_Limited_Supervision"><img class="cover" src="/postimages/Efficient-Deep-Embedded-Subspace-Clustering/image-20241004113308304.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Image_Manipulation_Detection_With_Implicit_Neural_Representation_and_Limited_Supervision</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="comment-tools"><div class="comment-randomInfo"><a onclick="addRandomCommentInfo()" href="javascript:void(0)" rel="external nofollow" data-pjax-state="">匿名评论</a></div></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div><script>function addRandomCommentInfo() {
  if (!confirm('开启匿名评论后，任何人将无法回复你的评论（包括博主），是否开启？')) {
    return;
  }
  var inputElements = document.getElementsByClassName('el-input__inner');
  const adjectives = ['幽默的', '豁达的', '温暖的', '优雅的', '活泼的', '迷人的', '甜美的', '聪明的', '坚定的', '善于思考的'];
  const nouns = ['橙子', '茄子', '西瓜', '辣椒', '草莓', '葡萄', '胡萝卜', '柠檬', '苹果', '香蕉'];
  for(var i = 0; i < inputElements.length; i++) {
    var input = inputElements[i];
    var name = input.getAttribute('name');
    const randomAdj = adjectives[Math.floor(Math.random() * adjectives.length)];
    const randomNoun = nouns[Math.floor(Math.random() * nouns.length)];

    switch (name) {
      case 'nick':
        input.value = `${randomAdj}${randomNoun}`;
        break;
      case 'mail':
        input.value = 'zhaozw-szu@users.noreply.github.com';
        break;
      case 'link':
        input.value = 'https://zhaozw-szu.github.io/';
        break;
      default:
        break;
    }
  }  
}</script></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Zhaozw</div><div class="author-info__description">人完成了引以为豪的事,才能够感到荣耀，否则,虚伪的自豪只会腐蚀心灵。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">91</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhaozw-szu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zhaozw-szu" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="/2300432033@email.szu.edu.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">可以用表情包和匿名评论了</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">1介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">2相关工作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-text">3方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B0"><span class="toc-text">3.1框架概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81transformer%E7%BB%84%E4%BB%B6"><span class="toc-text">3.2动态transformer组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E6%84%9F%E7%9F%A5%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-text">3.3特征重要性感知的注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E6%80%A7%E6%84%9F%E7%9F%A5%E7%9A%84%E5%8C%BA%E5%9F%9F%E5%88%86%E5%8C%BA"><span class="toc-text">重要性感知的区域分区。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E5%90%88%E8%A7%84%E6%A8%A1%E5%88%86%E9%85%8D"><span class="toc-text">聚合规模分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E9%80%82%E5%BA%94token%E8%81%9A%E5%90%88ata"><span class="toc-text">自适应token聚合ATA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E6%84%9F%E7%9F%A5%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9Bfia"><span class="toc-text">特征重要性感知的注意力FIA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-text">3.4动态解码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-text">3.5优化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-text">4实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-text">4.1实验设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">数据集。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87"><span class="toc-text">指标。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8E%E6%9C%80%E6%96%B0%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">4.2与最新方法的比较</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E9%87%8F%E6%AF%94%E8%BE%83"><span class="toc-text">定量比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E6%80%A7%E6%AF%94%E8%BE%83"><span class="toc-text">定性比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%B2%81%E6%A3%92%E6%80%A7%E5%88%86%E6%9E%90"><span class="toc-text">鲁棒性分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E5%88%86%E6%9E%90"><span class="toc-text">4.3消融分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E6%84%9F%E7%9F%A5%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">特征重要性感知的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">动态网络结构的影响</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">5结论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#acknowledgements"><span class="toc-text">Acknowledgements</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Zhaozw</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/8.13.8/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script defer src="https://npm.elemecdn.com/swiper@8.4.2/swiper-bundle.min.js"></script><script defer data-pjax src="/js/custom/swiper_init.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'all'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
  //- console.log('MathJax loaded')
} else {
  // 重置 TeX 状态并重新渲染
  MathJax.startup.promise.then(() => {
    MathJax.texReset();  // 重置 TeX 编号等状态
    MathJax.typesetPromise();
  });

  //- MathJax.startup.document.state(0)
  //- MathJax.texReset()
  //- MathJax.typesetPromise()
  //- console.log('MathJax reset')
}</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://zhaozw.netlify.app/.netlify/functions/twikoo',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://zhaozw.netlify.app/.netlify/functions/twikoo',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script async defer src="/config/js/categoryBar.js"></script><script type="text/javascript" src="/config/js/about.js"></script><script async src="/config/js/waterfall.js"></script><script defer src="/config/js/essay.js"></script><script defer src="/config/js/emoticon.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>